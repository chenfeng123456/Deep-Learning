\documentclass{article}

%文献引用，标准类型为plain
%\usepackage[hyperref=true,backend=biber,sorting=none,backref=true]{biblatex}
%\addbibresource{ref.bib}
\bibliographystyle{plain}
\usepackage{cite}


%超链接
\usepackage[pdftex,linkcolor=yellow,citecolor=red,backref=page]{hyperref}
\hypersetup{
bookmarks=true,
colorlinks=true,
linkcolor=blue
}



%添加首行缩进
\usepackage{indentfirst}
\setlength{\parindent}{2em}


%改变页边距
\usepackage[a4paper,left=20mm,right=20mm,top=10mm,bottom=10mm]{geometry}

\title{Literature Review}
\author{Guorui Lu}
\date{2018.8.15}
\begin{document}
\maketitle

\section{History and Significance}

\indent Synthesizing realistic photo from sketches drawn by human has been a challenging and hot problem for a long time. The research of this technique can be traced back to 2009\cite{Chen2009Sketch2Photo}. However, the technique of image generation and image-to-image transfer did not rise up until 2014, when the Generative Adversarial Nets(GAN)\cite{Goodfellow2014Generative} was proposed. Since then, variety of methods have been proposed to generate a more realistic photo for its broad application prospect. For example, police can use it to catch suspects through synthesised photos based on the drawn sketches, which requires that our photo should be as accurate as possible. As for the entertainment industry, we may need the model is able to generate images of multiple style, which is also a popular but difficult task.

\section{Mainstream Method}
\indent I will introduce the main method of this project from 2015 to the present because the actual reasearch on sketch-photo synthesis did't qppear until 2014, which I think is largely due to the fact that GAN \cite{Goodfellow2014Generative} was present in 2014. Before it, sketches were mainly used to do retrieval work \cite{Cao2010MindFinder, Eitz2010An, Hu2010Gradient, Wang2010MindFinder, Cao2011Edgel, Hu2011A, Hu2013A, Lin20143D}.


\subsection{Generative Adversarial Nets($GAN$)}

\subsubsection{Generative Adversarial Nets}
\indent The original GAN brought us a completely new idea. It is corresponding a minimax two-player game, which is simple and efficient. But it also has an obvious shortcoming that the constraint is too week so that we can't control what it will generate.

\subsubsection{cGAN and InfoGAN}
\indent Soon after the GAN's appearance, conditional GAN \cite{Mirza2014Conditional} was proposed, and then the InfoGAN \cite{Chen2016InfoGAN}. These two models are able to partly control the outputs by adding extra codes. However, the pictures they synthesize are still blurry and low-resolution.


\subsubsection{Pix2pix and Pix2pixHD}
\indent Pix2pix \cite{Isola2017Image} and pix2pixHD \cite{pix2pixHD} are two of the improved versions of the GANs. They took a big step forward to addressing the resolution issues. What they didn't resolve is that only when we have lots of paired images can we train the models.

\subsubsection{CycleGAN}
\indent Inspired by NLP, Jun-Yan Zhu and Taesung Park et al. came up with a new model named CycleGan \cite{Zhu2017Unpaired}. Although it has some drawbacks such as the high computing cost, CycleGAN still works very well for many problems. So I think I can apply it to my project.

\subsubsection{Rescent Work}
\indent Here I would show you some rescent work of sketch-photo in 2017 and 2018.
\begin{itemize}
\item SketchyGAN: Towards Diverse and Realistic Sketch to Image Synthesis\cite{Chen2018SketchyGAN}: \par
A new network structure proposed for generative task. It works better than retrieval model but the result is still blurry and low-resolution. Moreover, it is too faithful to the badly drawn pictures to keep the realism.

\item Facial Attributes Guided Deep Sketch-to-Photo Synthesis\cite{Kazemi2018Facial}: \par
This paper puts forward a method that add an auxiliary attribute discriminator to find the false attributes in the output of the generator. However, editing an attribute can cause unwanted structural edition of the image in some area, which is also the weakness of the previous models.

\item TextureGAN: Controlling Deep Image Synthesis with Texture Patches \cite{Xian2017TextureGAN} \par






\item Scribbler: Controlling Deep Image Synthesis with Sketch and Color\cite{Sangkloy2016Scribbler} \par
In this research, Pastsorn Sangkloy et al. use sketched with sparse color "scribbles" descided by human to generate a higher resolution and more diverse images. However, if users specifies uncommon or even wrong colors and shapes, this model would deem them correct. In addition, sometimes the boundaries between object parts or regions of defferent colors are likely to become vague.




\end{itemize}


\subsection{Deep Convolutional Neural Networks($DNNs$)}
\indent Although GANs has been a remarkable success in image generation field, deep convolutional neural network is still also an effective tool.  

%\begin{thebibliography}{}
%\addtolength{\itemsep}{-1.5ex}
%\bibitem [1]{Sketch2photo} Sketch2Photo T.Cao
%\end{thebibliography}

\bibliography{ref.bib}

%----处理参考文献的新方法
%\printbibliography

\end{document}